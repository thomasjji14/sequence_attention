{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare your data\n",
    "A raw data directory is required. It contains a comma separated file (CSV) and FASTA nucleic acid files for different samples. The directory structure of raw data is shown below:\n",
    "```\n",
    "raw_data\n",
    "â”‚   meta_data.csv  \n",
    "|   SAMPLE_1.fna\n",
    "|   SAMPLE_2.fna\n",
    "|   SAMPLE_3.fna\n",
    "|   ...\n",
    "```\n",
    "Formats of the required files is shown below:\n",
    "1. *meta_data.csv* format example:\n",
    "\n",
    "| sample_id | label  |\n",
    "|-----------|--------|\n",
    "| SAMPLE_1  | feces  |\n",
    "| SAMPLE_2  | tongue |\n",
    "| SAMPLE_3  | feces  |\n",
    "| SAMPLE_4  | skin   |\n",
    "| ...       | ...    |\n",
    "\n",
    "2. SAMPLE_1.fna format example:\n",
    "```\n",
    ">SAMPLE_1_1\n",
    "GCGAGCGAAGTTCGGAATTACTGGGCGTAAAGGGTGTGTA\n",
    ">SAMPLE_1_2\n",
    "GCGAGCGTTGTTCGGAACCACTGGGCGTAAAGGGTGTGTA\n",
    ">SAMPLE_1_3\n",
    "GCGAGCGTTGTTCGGAATTACTGGGCGTAGAGGGTGTGTA\n",
    "```\n",
    "\n",
    "#### 2. Edit the configuration file\n",
    "The user should edit the `config.py` to configure the model specs including the path to your data and the hyperparameters of the model. The following parameters should be edited based on your data. Please also carefully review the `config.py` file's comments for more detailed information for the rest of parameters and make sure you also modified them accordingly.\n",
    "1. `in_dir`: the absolute path to the raw data directory (should be created by the user in advance).\n",
    "2. `out_dir`: the absolute path to the processed data directory (should be created by the user in advance and files will be generated by this program).\n",
    "3. `num_train_samples_per_cls`: the number of training sample per class. Note that the rest of samples will be automatically placed in the testing set used for evaluation. If you decide to use all the data for training, then the testing set will be empty and then hence the downstreaming evaluation command won't work.\n",
    "4. `SEQLEN`: sequence length.\n",
    "5. `BASENUM`: the number of unique characters (nucleotides/amino acids) (e.g., for DNA reads, there are 4 major bases for DNA sequence input, therefore you can set `BASENUM` to 4).\n",
    "6, `Ty`: the number of target classes (`Ty` >= 2).\n",
    "7. `save_model_path`: the absolute path to the saved model directory (should be created by the user in advance).\n",
    "8. `n_workers`: this is used for a Keras function. It defines the number of threads generating batches in parallel. According to Kera, batches are computed in parallel on the CPU and passed on the fly onto the GPU for neural network computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sequence_attention import SeqAttModel, preprocess_data, preprocess_data_pickle\n",
    "from sequence_attention import DataGenerator, DataGeneratorUnlabeled, DataGeneratorPickle, DataGeneratorUnlabeledPickle\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Load the configuration information from `config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Preprocess the data\n",
    "\n",
    "There are three different ways to prepare the data: \n",
    "1. split each fna file into files that contain one read per file. Then the data generator for the deep learning model can quickly load reads and construct a batch of data. However, it can be very slow to split reads into individual files when you have millions of reads to split; \n",
    "2. convert each fna file to a pickle file with a python dictionary data structure (key is the unique sequence identifier and value is the actual sequence). Then the data generator can load a pickle file and look up for a read and construct a batch of data. It is way faster than the first method in preprocessing part but can be slower when the data generator constructs the training/testing batch. \n",
    "3. The fastest way is, of course, training and testing your model without using the data generator. Instead, permitted by the computer memory, users can load all the training data in memory and directly fit the model. In this way, there will be no additional I/O process. When designing this tool, we don't make any assumption on the computer memory at the user's disposal, therefore, this demo focuses on the second preprocessing method since it covers the most use cases. But if the users do have enough memory, they are more than welcome to fit the model without the generator function. We will talk about additional information about the third method in the model training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-Aug-21 22:21:57 - Processing raw data: 0.0% completed.\n",
      "05-Aug-21 22:21:58 - Processing raw data: 10.0% completed.\n",
      "05-Aug-21 22:21:58 - Processing raw data: 20.0% completed.\n",
      "05-Aug-21 22:21:58 - Processing raw data: 30.0% completed.\n"
     ]
    }
   ],
   "source": [
    "preprocess_data_pickle(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load metadata and initialize the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-Aug-21 22:22:04 - Model initialized.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "label_dict = pickle.load(open('{}/label_dict.pkl'.format(opt.out_dir), 'rb')) \n",
    "sample_to_label, read_meta_data = pickle.load(open('{}/meta_data.pkl'.format(opt.out_dir), 'rb'))\n",
    "partition = pickle.load(open('{}/train_test_split.pkl'.format(opt.out_dir), 'rb')) \n",
    "seq_att_model = SeqAttModel(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the summary of the model by running the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_cnv0 (Conv1D)       (None, 100, 256)     9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_bn0 (BatchNormaliza (None, 100, 256)     1024        convblock_0_cnv0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_a0 (Activation)     (None, 100, 256)     0           convblock_0_bn0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv0 (Conv1D)        (None, 100, 256)     590080      convblock_0_a0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn0 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a0 (Activation)      (None, 100, 256)     0           resblock_0_bn0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv1 (Conv1D)        (None, 100, 256)     590080      resblock_0_a0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn1 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a1 (Activation)      (None, 100, 256)     0           resblock_0_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv2 (Conv1D)        (None, 100, 256)     590080      resblock_0_a1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn2 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 256)     0           resblock_0_bn2[0][0]             \n",
      "                                                                 convblock_0_a0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a2 (Activation)      (None, 100, 256)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, 100, 128)     197120      resblock_0_a2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "att_dense_0 (TimeDistributed)   (None, 100, 16)      2064        LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "att_dense_final (TimeDistribute (None, 100, 1)       17          att_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "att_weights (Softmax)           (None, 100, 1)       0           att_dense_final[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "att_mul (Dot)                   (None, 1, 128)       0           att_weights[0][0]                \n",
      "                                                                 LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "att_emb (Flatten)               (None, 128)          0           att_mul[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           att_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,983,138\n",
      "Trainable params: 1,981,090\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_att_model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Prepare the data generator for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGeneratorPickle(partition['train'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n",
    "testing_generator = DataGeneratorPickle(partition['test'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: training without the generator (1)\n",
    "As mentioned in step 5, if you can fit all your training data in memory, you can directly train your model without using the slow data generator which does a lot of I/O operations on the fly. Take the training step as an example, all you need to prepare is an X and a y variable for training sequence data and training label data. Below, I show what the X and y look like using one batch of my demo training data. As you can see, the X is simply 1024 by 100 by 4 NumPy array. In your case, the first dimension (1024) should be the total number of training reads/sequences. Say you want to use 50 samples for training and each sample on average has 20,000 reads, then you will have around 100,000 reads for training in total. The second dimension (100) is the read/sequence length. You can trim all your reads to the same length or pad zeros to the end so that all the reads are in the same length. The last dimension (4) corresponds to the number of unique characters in your data. Say you are dealing with DNA sequences with no ambiguity, there will be 4 characters, `ACGT`. We are performing one hot coding. So nucleotide `A` is coded as $[1, 0, 0, 0]$, `G` is codes as $[0, 0, 1, 0]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 100, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Train and evluate the model\n",
    "If your meomory is limited, data generator load only a subset of the whole training data into memory for training. This process costs additional I/0 operations in exchange for less memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_att_model.train_generator(training_generator, n_workers=opt.n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_att_model.evaluate_generator(testing_generator, n_workers=opt.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: training without the generator (2)\n",
    "For those of you who have enoguh memory, you can avoid additional I/O operations by training the model without the data generator. Once you have the training data X and y ready (see ***Note: training without the generator (1)*** for details), you can run the following command to train your model directly without the data generator function. This is the fastest training method given your training data fits into your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 15ms/step - loss: 0.7204 - acc: 0.5127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34e82a9ef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_att_model.model.fit(X, y, batch_size=opt.batch_size, epochs=opt.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Model interpretation and sequence visualization\n",
    "This step is exploratory and completely depends on you. To get started, please review the following data requirements:\n",
    "\n",
    "1. Prepare the X_visual (N by SEQ_LEN by NUMBASE) in *numpy array*, see also ***Note: training without the generator (1)***\n",
    "2. y_visual (phenotypic labels in integers) in *numpy array*, use `label_dict` as the label to integer map.\n",
    "3. a list of taxonomic labels of those sequences (e.g., genus level labels as python strings). \n",
    "\n",
    "Once you have the data ready, run the following commands to plot embedding and attention weights visualization figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, attention_weights, sequence_embedding = seq_att_model.extract_weigths(X_visual)\n",
    "from sequence_attention import SeqVisualUnit\n",
    "idx_to_label = {label_dict[label]: label for label in label_dict}\n",
    "seq_visual_unit = SeqVisualUnit(X_visual, y_visual, idx_to_label, taxa_label_list, \n",
    "                                prediction, attention_weights, sequence_embedding, 'Figures')\n",
    "seq_visual_unit.plot_embedding()\n",
    "## Let's say you want to plot the attention weights of \"Prevotella\" reads\n",
    "seq_visual_unit.plot_attention('Prevotella')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code snippet above, we also need , *label_dict* (phenotypic labels to integer dictionary saved in `opt.out_dir/label_dict.pkl` by the previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: a pretrain model and visualization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sequence_attention import SeqAttModel, preprocess_data, preprocess_data_pickle\n",
    "from sequence_attention import DataGenerator, DataGeneratorUnlabeled, DataGeneratorPickle, DataGeneratorUnlabeledPickle\n",
    "from config import Config\n",
    "\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.Ty=5\n",
    "opt.if_lstm=2\n",
    "opt.n_lstm_node=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05-Aug-21 22:43:56 - Model initialized.\n"
     ]
    }
   ],
   "source": [
    "seq_att_model = SeqAttModel(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_cnv0 (Conv1D)       (None, 100, 256)     9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_bn0 (BatchNormaliza (None, 100, 256)     1024        convblock_0_cnv0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "convblock_0_a0 (Activation)     (None, 100, 256)     0           convblock_0_bn0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv0 (Conv1D)        (None, 100, 256)     590080      convblock_0_a0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn0 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a0 (Activation)      (None, 100, 256)     0           resblock_0_bn0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv1 (Conv1D)        (None, 100, 256)     590080      resblock_0_a0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn1 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a1 (Activation)      (None, 100, 256)     0           resblock_0_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_cnv2 (Conv1D)        (None, 100, 256)     590080      resblock_0_a1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_bn2 (BatchNormalizat (None, 100, 256)     1024        resblock_0_cnv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 256)     0           resblock_0_bn2[0][0]             \n",
      "                                                                 convblock_0_a0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "resblock_0_a2 (Activation)      (None, 100, 256)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (Bidirectional)            (None, 100, 64)      164352      resblock_0_a2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 64)      0           LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "att_dense_0 (TimeDistributed)   (None, 100, 16)      1040        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "att_dense_final (TimeDistribute (None, 100, 1)       17          att_dense_0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "att_weights (Softmax)           (None, 100, 1)       0           att_dense_final[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "att_mul (Dot)                   (None, 1, 64)        0           att_weights[0][0]                \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "att_emb (Flatten)               (None, 64)           0           att_mul[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           att_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 5)            325         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,949,542\n",
      "Trainable params: 1,947,494\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_att_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_att_model.model.load_weights('final_ag_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
