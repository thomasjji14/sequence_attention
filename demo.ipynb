{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sequence_attention import SeqAttModel, preprocess_data, preprocess_data_pickle\n",
    "from sequence_attention import DataGenerator, DataGeneratorUnlabeled, DataGeneratorPickle, DataGeneratorUnlabeledPickle\n",
    "from config import Config\n",
    "\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Oct-20 23:48:37 - Processing raw data: 0.0% completed.\n",
      "26-Oct-20 23:59:58 - Processing raw data: 10.0% completed.\n",
      "27-Oct-20 00:11:09 - Processing raw data: 20.0% completed.\n",
      "27-Oct-20 00:22:22 - Processing raw data: 30.0% completed.\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(opt)\n",
    "\n",
    "# preprocess_data_pickle(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-Oct-20 00:39:23 - Model initialized.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "label_dict = pickle.load(open('{}/label_dict.pkl'.format(opt.out_dir), 'rb')) \n",
    "sample_to_label, read_meta_data = pickle.load(open('{}/meta_data.pkl'.format(opt.out_dir), 'rb'))\n",
    "partition = pickle.load(open('{}/train_test_split.pkl'.format(opt.out_dir), 'rb')) \n",
    "seq_att_model = SeqAttModel(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n",
    "testing_generator = DataGenerator(partition['test'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGeneratorPickle(partition['train'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n",
    "testing_generator = DataGeneratorPickle(partition['test'], sample_to_label, label_dict, \n",
    "                                   dim=(opt.SEQLEN,opt.BASENUM), batch_size=opt.batch_size, shuffle=opt.shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(opt):\n",
    "    '''\n",
    "    preprocessing the data\n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(opt.out_dir):\n",
    "        os.makedirs(opt.out_dir)\n",
    "    \n",
    "    meta_data = pd.read_csv('{}/meta_data.csv'.format(opt.in_dir), dtype='str')\n",
    "    \n",
    "    label_list = sorted(meta_data['label'].unique())\n",
    "    \n",
    "    label_dict = {}\n",
    "    for idx, label in enumerate(label_list):\n",
    "        label_dict[label] = idx\n",
    "        \n",
    "    pickle.dump(label_dict, open('{}/label_dict.pkl'.format(opt.out_dir), 'wb'))\n",
    "    \n",
    "    for label in label_list:\n",
    "        label_dir = '{}/{}'.format(opt.out_dir, label)\n",
    "        if os.path.exists(label_dir):\n",
    "            continue\n",
    "        os.makedirs(label_dir)\n",
    "        \n",
    "    read_meta_data = {}\n",
    "    STEP = meta_data.shape[0] // 10 if meta_data.shape[0] > 10 else 1\n",
    "    for idx in range(meta_data.shape[0]):\n",
    "        if idx % STEP == 0:\n",
    "            logging.info('Processing raw data: {:.1f}% completed.'.format(10 * idx / STEP))\n",
    "        sample_id, label = meta_data.iloc[idx]['sample_id'], meta_data.iloc[idx]['label']\n",
    "\n",
    "        read_meta_data[sample_id] = fna_to_dict(sample_id, label, opt.in_dir, opt.out_dir)\n",
    "    \n",
    "    min_num_sample = min([meta_data[meta_data['label']==label].shape[0] for label in label_list])\n",
    "    \n",
    "    num_train_samples_per_cls = opt.num_train_samples_per_cls\n",
    "    num_train_samples_per_cls = num_train_samples_per_cls if num_train_samples_per_cls < min_num_sample else min_num_sample\n",
    "    \n",
    "    partition = train_test_split(meta_data, num_train_samples_per_cls)\n",
    "    \n",
    "    \n",
    "    sample_to_label = {}\n",
    "    for idx in range(meta_data.shape[0]):\n",
    "        sample_id, label = meta_data.iloc[idx]['sample_id'], meta_data.iloc[idx]['label']\n",
    "        sample_to_label[sample_id] = label\n",
    "\n",
    "    pickle.dump([sample_to_label, read_meta_data], open('{}/meta_data.pkl'.format(opt.out_dir), 'wb'))\n",
    "    \n",
    "    train_list = []\n",
    "    for sample_id in partition['train']:\n",
    "        train_list.extend([('{}/{}/{}.pkl'.format(opt.out_dir, sample_to_label[sample_id], sample_id), read_id) for read_id in read_meta_data[sample_id]])\n",
    "    test_list = []\n",
    "    for sample_id in partition['test']:\n",
    "        test_list.extend([('{}/{}/{}.pkl'.format(opt.out_dir, sample_to_label[sample_id], sample_id), read_id) for read_id in read_meta_data[sample_id]])\n",
    "    \n",
    "    read_partition = {'train': train_list, 'test': test_list}\n",
    "    pickle.dump(read_partition, open('{}/train_test_split.pkl'.format(opt.out_dir), 'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fna_to_dict(sample_id, label, in_dir, out_dir):\n",
    "    '''\n",
    "    convert fna file to dictionary\n",
    "    '''\n",
    "    \n",
    "    out_name = '{}/{}/{}.pkl'.format(out_dir, label, sample_id)\n",
    "    \n",
    "    meta_data_read_list = []\n",
    "    read = ''\n",
    "    f_sample = open(filename)\n",
    "    read_dict = {}\n",
    "    for line in f_sample:\n",
    "        if line[0] == '>':\n",
    "            if len(read) != 0:\n",
    "                read_dict[header] = read\n",
    "                meta_data_read_list.append(header)\n",
    "                read = ''\n",
    "            read += line\n",
    "            header = line[1:].strip()\n",
    "        else:\n",
    "            read += line\n",
    "    if len(read) != 0:\n",
    "        read_dict[header] = read\n",
    "        meta_data_read_list.append(header)\n",
    "    f_sample.close()\n",
    "    pickle.dump(read_dict, open(out_name, 'wb'))\n",
    "    return meta_data_read_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((self.batch_size, *self.dim))\n",
    "if self.n_classes == 2:\n",
    "    y = np.zeros((self.batch_size,), dtype=int)\n",
    "else:\n",
    "    y = np.zeros((self.batch_size, self.n_classes), dtype=int)\n",
    "# Generate data\n",
    "for i, file in enumerate(list_IDs_temp):\n",
    "    # Store sample\n",
    "    sample_file_name = file[0]\n",
    "    sample_id = sample_file_name.split('/')[-1][:-4]\n",
    "    header = file[1]\n",
    "    read_dict = pickle.load(open(sample_file_name, 'rb'))\n",
    "    seq = read_dict[header]\n",
    "\n",
    "    seq_tmp = seq if len(seq) < self.dim[0] else seq[:self.dim[0]]\n",
    "    seq_coded = self.__seq_mapper(seq_tmp)\n",
    "    X[i,] = seq_coded\n",
    "    if self.n_classes == 2:\n",
    "        y[i] = self.sample_to_label[sample_id]\n",
    "    else:\n",
    "        y[i,self.label_dict[self.sample_to_label[sample_id]]] = 1\n",
    "\n",
    "return X, y "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
